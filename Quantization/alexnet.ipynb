{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6810129,"sourceType":"datasetVersion","datasetId":3917752}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports here\nimport torch\nimport PIL\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom torchvision import datasets, transforms, models\nfrom torch import nn\nfrom torch import optim\nfrom collections import OrderedDict\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","metadata":{"execution":{"iopub.status.busy":"2024-01-13T17:26:34.569299Z","iopub.execute_input":"2024-01-13T17:26:34.570232Z","iopub.status.idle":"2024-01-13T17:26:34.584788Z","shell.execute_reply.started":"2024-01-13T17:26:34.570186Z","shell.execute_reply":"2024-01-13T17:26:34.583278Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from time import time","metadata":{"execution":{"iopub.status.busy":"2024-01-13T17:26:34.586821Z","iopub.execute_input":"2024-01-13T17:26:34.587188Z","iopub.status.idle":"2024-01-13T17:26:34.597324Z","shell.execute_reply.started":"2024-01-13T17:26:34.587157Z","shell.execute_reply":"2024-01-13T17:26:34.596113Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\ndata_dir = '/kaggle/input/'\ntrain_dir = data_dir + '/train'\n\n# Define your transformations\ntrain_transforms = transforms.Compose([\n    transforms.RandomRotation(30),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Load all the images from the train folder\nall_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n\n# Calculate the sizes for train, validation, and test sets\ntotal_size = len(all_data)\ntrain_size = int(0.7 * total_size)\ntest_size = int(0.2 * total_size)\nvalid_size = total_size - train_size - test_size\n\n# Use random_split to split the dataset\ntrain_data, valid_data, test_data = torch.utils.data.random_split(all_data, [train_size, valid_size, test_size])\n\n# Create data loaders\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size=50, shuffle=False)\nvalidloader = torch.utils.data.DataLoader(valid_data, batch_size=50)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=50)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T17:26:34.606859Z","iopub.execute_input":"2024-01-13T17:26:34.607723Z","iopub.status.idle":"2024-01-13T17:26:35.832545Z","shell.execute_reply.started":"2024-01-13T17:26:34.607676Z","shell.execute_reply":"2024-01-13T17:26:35.831528Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Load a pre-trained network \nmodel = models.alexnet(pretrained=True)\nmodel.name = \"alexnet\"\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-01-13T17:26:35.835002Z","iopub.execute_input":"2024-01-13T17:26:35.835730Z","iopub.status.idle":"2024-01-13T17:26:36.707906Z","shell.execute_reply.started":"2024-01-13T17:26:35.835684Z","shell.execute_reply":"2024-01-13T17:26:36.706456Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Freeze parameters so we don't backprop through them\nfor param in model.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-01-13T17:26:36.709275Z","iopub.execute_input":"2024-01-13T17:26:36.710218Z","iopub.status.idle":"2024-01-13T17:26:36.716186Z","shell.execute_reply.started":"2024-01-13T17:26:36.710180Z","shell.execute_reply":"2024-01-13T17:26:36.714928Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Define a new, untrainted feed-forward network as a classifier, using ReLU activations and dropout\nclassifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(9216, 4096, bias=True)),\n                          ('relu1', nn.ReLU()),\n                          ('dropout1', nn.Dropout(p=0.5)),\n                          ('fc2', nn.Linear(4096, 14, bias=True)),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))\n    \nmodel.classifier = classifier","metadata":{"execution":{"iopub.status.busy":"2024-01-13T17:26:36.717485Z","iopub.execute_input":"2024-01-13T17:26:36.717881Z","iopub.status.idle":"2024-01-13T17:26:37.154439Z","shell.execute_reply.started":"2024-01-13T17:26:36.717850Z","shell.execute_reply":"2024-01-13T17:26:37.153357Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Device agnostic code, automatically uses CUDA if it's enabled\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-01-13T17:26:37.157386Z","iopub.execute_input":"2024-01-13T17:26:37.157764Z","iopub.status.idle":"2024-01-13T17:26:37.166273Z","shell.execute_reply.started":"2024-01-13T17:26:37.157733Z","shell.execute_reply":"2024-01-13T17:26:37.165024Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"code","source":"# change to device\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T17:26:37.167520Z","iopub.execute_input":"2024-01-13T17:26:37.167845Z","iopub.status.idle":"2024-01-13T17:26:37.179418Z","shell.execute_reply.started":"2024-01-13T17:26:37.167816Z","shell.execute_reply":"2024-01-13T17:26:37.178236Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n    (relu1): ReLU()\n    (dropout1): Dropout(p=0.5, inplace=False)\n    (fc2): Linear(in_features=4096, out_features=14, bias=True)\n    (output): LogSoftmax(dim=1)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Define loss and optimizer\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n\n# Define deep learning method\nepochs = 5\nprint_every = 30 # Prints every 30 images out of batch of 50 images\nsteps = 0","metadata":{"execution":{"iopub.status.busy":"2024-01-13T17:26:37.180697Z","iopub.execute_input":"2024-01-13T17:26:37.181037Z","iopub.status.idle":"2024-01-13T17:26:37.188943Z","shell.execute_reply.started":"2024-01-13T17:26:37.181008Z","shell.execute_reply":"2024-01-13T17:26:37.187918Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Implement a function for the validation pass\ndef validation(model, testloader, criterion):\n    test_loss = 0\n    accuracy = 0\n    \n    for ii, (inputs, labels) in enumerate(testloader):\n        \n        # Uncomment below line if gpu is available\n        #inputs, labels = inputs.to(device), labels.to(device)\n        \n        output = model.forward(inputs)\n        test_loss += criterion(output, labels).item()\n        \n        ps = torch.exp(output)\n        equality = (labels.data == ps.max(dim=1)[1])\n        accuracy += equality.type(torch.FloatTensor).mean()\n    \n    return test_loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-01-13T17:26:37.190369Z","iopub.execute_input":"2024-01-13T17:26:37.190779Z","iopub.status.idle":"2024-01-13T17:26:37.203891Z","shell.execute_reply.started":"2024-01-13T17:26:37.190745Z","shell.execute_reply":"2024-01-13T17:26:37.202801Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Train the classifier layers using backpropogation using the pre-trained network to get features\n\nprint(\"Training process initializing .....\\n\")\n\nfor e in range(epochs):\n    running_loss = 0\n    model.train() # Technically not necessary, setting this for good measure\n    \n    for ii, (inputs, labels) in enumerate(trainloader):\n        steps += 1\n        \n        # Uncomment below line if gpu is available\n        #inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward and backward passes\n        outputs = model.forward(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n        if steps % print_every == 0:\n            model.eval()\n\n            with torch.no_grad():\n                valid_loss, accuracy = validation(model, validloader, criterion)\n            \n            print(\"Epoch: {}/{} | \".format(e+1, epochs),\n                  \"Training Loss: {:.4f} | \".format(running_loss/print_every),\n                  \"Validation Loss: {:.4f} | \".format(valid_loss/len(validloader)),\n                  \"Validation Accuracy: {:.4f}\".format(accuracy/len(validloader)))\n            \n            running_loss = 0\n            model.train()\n\nprint(\"\\nTraining process is now complete!!\")","metadata":{"execution":{"iopub.status.busy":"2024-01-13T17:26:37.205407Z","iopub.execute_input":"2024-01-13T17:26:37.205756Z","iopub.status.idle":"2024-01-13T18:03:48.872409Z","shell.execute_reply.started":"2024-01-13T17:26:37.205728Z","shell.execute_reply":"2024-01-13T18:03:48.871153Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Training process initializing .....\n\nEpoch: 1/5 |  Training Loss: 4.6187 |  Validation Loss: 1.1444 |  Validation Accuracy: 0.7164\nEpoch: 1/5 |  Training Loss: 1.1984 |  Validation Loss: 0.8339 |  Validation Accuracy: 0.7245\nEpoch: 1/5 |  Training Loss: 0.9206 |  Validation Loss: 0.7471 |  Validation Accuracy: 0.7600\nEpoch: 1/5 |  Training Loss: 0.9151 |  Validation Loss: 0.7173 |  Validation Accuracy: 0.7629\nEpoch: 1/5 |  Training Loss: 0.9804 |  Validation Loss: 0.7193 |  Validation Accuracy: 0.7710\nEpoch: 1/5 |  Training Loss: 0.8576 |  Validation Loss: 0.6768 |  Validation Accuracy: 0.7833\nEpoch: 2/5 |  Training Loss: 0.4843 |  Validation Loss: 0.6756 |  Validation Accuracy: 0.8014\nEpoch: 2/5 |  Training Loss: 0.8015 |  Validation Loss: 0.6858 |  Validation Accuracy: 0.7836\nEpoch: 2/5 |  Training Loss: 0.8842 |  Validation Loss: 0.6580 |  Validation Accuracy: 0.7969\nEpoch: 2/5 |  Training Loss: 0.7931 |  Validation Loss: 0.6500 |  Validation Accuracy: 0.7917\nEpoch: 2/5 |  Training Loss: 0.8176 |  Validation Loss: 0.6760 |  Validation Accuracy: 0.7738\nEpoch: 2/5 |  Training Loss: 0.8339 |  Validation Loss: 0.6462 |  Validation Accuracy: 0.8057\nEpoch: 3/5 |  Training Loss: 0.1777 |  Validation Loss: 0.6671 |  Validation Accuracy: 0.7740\nEpoch: 3/5 |  Training Loss: 0.7816 |  Validation Loss: 0.6701 |  Validation Accuracy: 0.7819\nEpoch: 3/5 |  Training Loss: 0.8463 |  Validation Loss: 0.6489 |  Validation Accuracy: 0.8017\nEpoch: 3/5 |  Training Loss: 0.7898 |  Validation Loss: 0.6227 |  Validation Accuracy: 0.8040\nEpoch: 3/5 |  Training Loss: 0.7534 |  Validation Loss: 0.7148 |  Validation Accuracy: 0.7705\nEpoch: 3/5 |  Training Loss: 0.8376 |  Validation Loss: 0.6772 |  Validation Accuracy: 0.7924\nEpoch: 3/5 |  Training Loss: 0.8020 |  Validation Loss: 0.6598 |  Validation Accuracy: 0.7995\nEpoch: 4/5 |  Training Loss: 0.6194 |  Validation Loss: 0.6793 |  Validation Accuracy: 0.7931\nEpoch: 4/5 |  Training Loss: 0.7660 |  Validation Loss: 0.6649 |  Validation Accuracy: 0.7843\nEpoch: 4/5 |  Training Loss: 0.7725 |  Validation Loss: 0.6359 |  Validation Accuracy: 0.7990\nEpoch: 4/5 |  Training Loss: 0.8031 |  Validation Loss: 0.6646 |  Validation Accuracy: 0.7869\nEpoch: 4/5 |  Training Loss: 0.7940 |  Validation Loss: 0.6885 |  Validation Accuracy: 0.8057\nEpoch: 4/5 |  Training Loss: 0.7880 |  Validation Loss: 0.6150 |  Validation Accuracy: 0.8088\nEpoch: 5/5 |  Training Loss: 0.3791 |  Validation Loss: 0.6476 |  Validation Accuracy: 0.7964\nEpoch: 5/5 |  Training Loss: 0.7172 |  Validation Loss: 0.6287 |  Validation Accuracy: 0.8000\nEpoch: 5/5 |  Training Loss: 0.7087 |  Validation Loss: 0.6569 |  Validation Accuracy: 0.7945\nEpoch: 5/5 |  Training Loss: 0.7478 |  Validation Loss: 0.6319 |  Validation Accuracy: 0.8014\nEpoch: 5/5 |  Training Loss: 0.7042 |  Validation Loss: 0.5931 |  Validation Accuracy: 0.8205\nEpoch: 5/5 |  Training Loss: 0.7273 |  Validation Loss: 0.6156 |  Validation Accuracy: 0.8079\n\nTraining process is now complete!!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing your network\n\nIt's good practice to test your trained network on test data, images the network has never seen either in training or validation. This will give you a good estimate for the model's performance on completely new images. Run the test images through the network and measure the accuracy, the same way you did validation. You should be able to reach around 70% accuracy on the test set if the model has been trained well.","metadata":{}},{"cell_type":"code","source":"all_labels = []\nall_predictions = []","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:06:08.354718Z","iopub.execute_input":"2024-01-13T18:06:08.355139Z","iopub.status.idle":"2024-01-13T18:06:08.360162Z","shell.execute_reply.started":"2024-01-13T18:06:08.355106Z","shell.execute_reply":"2024-01-13T18:06:08.359247Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"Try to load all image tensors to gpu before the loop","metadata":{}},{"cell_type":"code","source":"# TODO: Do validation on the test set\n# Do validation on the test set\nfrom time import time\ncorrect = 0\ntotal = 0\nstart_time = time()\nwith torch.no_grad():\n    model.eval()\n    for images, labels in testloader:\n        all_labels.extend(labels.numpy())\n        # Uncomment below line if gpu is available\n        #images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        #predicted_tensor_cpu = predicted.to('cpu')\n        all_predictions.extend(predicted.numpy())\nend_time = time()\nprint(\"Time: \",end_time - start_time)\n\nprint('Accuracy achieved by the network on test images is: %d%%' % (100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:03:48.881574Z","iopub.execute_input":"2024-01-13T18:03:48.882006Z","iopub.status.idle":"2024-01-13T18:04:59.906952Z","shell.execute_reply.started":"2024-01-13T18:03:48.881975Z","shell.execute_reply":"2024-01-13T18:04:59.905699Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Time:  71.00774002075195\nAccuracy achieved by the network on test images is: 82%\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(all_labels))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:04:59.908458Z","iopub.execute_input":"2024-01-13T18:04:59.909282Z","iopub.status.idle":"2024-01-13T18:04:59.915787Z","shell.execute_reply.started":"2024-01-13T18:04:59.909242Z","shell.execute_reply":"2024-01-13T18:04:59.914476Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"2728\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(all_predictions))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:04:59.916854Z","iopub.execute_input":"2024-01-13T18:04:59.917196Z","iopub.status.idle":"2024-01-13T18:04:59.927472Z","shell.execute_reply.started":"2024-01-13T18:04:59.917165Z","shell.execute_reply":"2024-01-13T18:04:59.926472Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"2728\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport numpy as np\nall_labels = np.array(all_labels)\nall_predictions = np.array(all_predictions)\n\n# Calculate the confusion matrix\ncm = confusion_matrix(all_labels, all_predictions)\n\nprint(\"Confusion Matrix:\")\nprint(cm)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:04:59.931734Z","iopub.execute_input":"2024-01-13T18:04:59.932594Z","iopub.status.idle":"2024-01-13T18:05:00.125341Z","shell.execute_reply.started":"2024-01-13T18:04:59.932538Z","shell.execute_reply":"2024-01-13T18:05:00.123885Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Confusion Matrix:\n[[130   4   0   0   1   9   1   1   2   1   1   0   1   1]\n [  6 131   0   0   2   4   4   0   2  18   3   0   1   2]\n [  0   1 196   3   1   0   1   6   0   0   0   3   0   0]\n [  1   4   2 112   7   8   5  31   4   3   2   7   0   4]\n [  1   8   1  23 147   5   2   8   0   0   1   1   4   3]\n [  1   9   0   2   0 147   5   0   0   4   7   1   8   1]\n [  4   9   0   2   0   8 169   1   3   0   0   0   6   2]\n [  2   1   9  12   3   0   3 160   0   0   1   2   0   0]\n [  2   1   0   2   0   1   6   1 180   0   0   0   0   0]\n [  0  28   0   0   0   3   1   0   0 195   3   0   0   1]\n [  0   2   0   0   2  28   3   0   0   4 137   0  15   0]\n [  1   0   6   4   0   0   3   8   0   0   0 171   0   0]\n [  0   2   0   0   2  10   0   1   0   1   2   0 193   0]\n [  0  12   0   1   0   6   5   0   0   1   0   0   2 170]]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nreport = classification_report(all_labels, all_predictions)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:05:00.127289Z","iopub.execute_input":"2024-01-13T18:05:00.128110Z","iopub.status.idle":"2024-01-13T18:05:00.153913Z","shell.execute_reply.started":"2024-01-13T18:05:00.128062Z","shell.execute_reply":"2024-01-13T18:05:00.152669Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.88      0.86      0.87       152\n           1       0.62      0.76      0.68       173\n           2       0.92      0.93      0.92       211\n           3       0.70      0.59      0.64       190\n           4       0.89      0.72      0.80       204\n           5       0.64      0.79      0.71       185\n           6       0.81      0.83      0.82       204\n           7       0.74      0.83      0.78       193\n           8       0.94      0.93      0.94       193\n           9       0.86      0.84      0.85       231\n          10       0.87      0.72      0.79       191\n          11       0.92      0.89      0.90       193\n          12       0.84      0.91      0.88       211\n          13       0.92      0.86      0.89       197\n\n    accuracy                           0.82      2728\n   macro avg       0.83      0.82      0.82      2728\nweighted avg       0.83      0.82      0.82      2728\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming your train_data is a Subset object\noriginal_dataset = train_data.dataset\n\n# Create a class_to_idx mapping\nmodel.class_to_idx = {class_name: idx for idx, class_name in enumerate(original_dataset.classes)}\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:05:00.155388Z","iopub.execute_input":"2024-01-13T18:05:00.155849Z","iopub.status.idle":"2024-01-13T18:05:00.162195Z","shell.execute_reply.started":"2024-01-13T18:05:00.155811Z","shell.execute_reply":"2024-01-13T18:05:00.160974Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(model.class_to_idx)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:05:00.163360Z","iopub.execute_input":"2024-01-13T18:05:00.163716Z","iopub.status.idle":"2024-01-13T18:05:00.176049Z","shell.execute_reply.started":"2024-01-13T18:05:00.163685Z","shell.execute_reply":"2024-01-13T18:05:00.174662Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"{'astilbe': 0, 'bellflower': 1, 'black_eyed_susan': 2, 'calendula': 3, 'california_poppy': 4, 'carnation': 5, 'common_daisy': 6, 'coreopsis': 7, 'dandelion': 8, 'iris': 9, 'rose': 10, 'sunflower': 11, 'tulip': 12, 'water_lily': 13}\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint = {'architecture': model.name,\n             'classifier': model.classifier,\n             'class_to_idx': model.class_to_idx,\n             'state_dict': model.state_dict()}\n\ntorch.save(checkpoint, 'model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:05:00.177870Z","iopub.execute_input":"2024-01-13T18:05:00.178269Z","iopub.status.idle":"2024-01-13T18:05:00.391598Z","shell.execute_reply.started":"2024-01-13T18:05:00.178235Z","shell.execute_reply":"2024-01-13T18:05:00.390522Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# TODO: Write a function that loads a checkpoint and rebuilds the model\n# Write a function that loads a checkpoint and rebuilds the model\ndef load_checkpoint():\n    \"\"\"\n    Loads deep learning model checkpoint.\n    \"\"\"\n    \n    # Load the saved file\n    checkpoint = torch.load(\"/kaggle/working/model.pth\")\n    \n    # Download pretrained model\n    model = models.alexnet(pretrained=True);\n    \n    # Freeze parameters so we don't backprop through them\n    for param in model.parameters(): param.requires_grad = False\n    \n    # Load stuff from checkpoint\n    model.class_to_idx = checkpoint['class_to_idx']\n    model.classifier = checkpoint['classifier']\n    model.load_state_dict(checkpoint['state_dict'])\n\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:05:00.393470Z","iopub.execute_input":"2024-01-13T18:05:00.394014Z","iopub.status.idle":"2024-01-13T18:05:00.402899Z","shell.execute_reply.started":"2024-01-13T18:05:00.393967Z","shell.execute_reply":"2024-01-13T18:05:00.401667Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# QUANTIZATION","metadata":{}},{"cell_type":"code","source":"model_fp16 = load_checkpoint()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:08:08.180684Z","iopub.execute_input":"2024-01-13T18:08:08.181258Z","iopub.status.idle":"2024-01-13T18:08:09.161211Z","shell.execute_reply.started":"2024-01-13T18:08:08.181215Z","shell.execute_reply":"2024-01-13T18:08:09.160274Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"weights = model.state_dict()\nprint(weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fp16.half()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights_half = model_fp16.state_dict()\nprint(weights_half['features.0.weight'].dtype)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:08:25.511702Z","iopub.execute_input":"2024-01-13T18:08:25.512099Z","iopub.status.idle":"2024-01-13T18:08:25.519404Z","shell.execute_reply.started":"2024-01-13T18:08:25.512069Z","shell.execute_reply":"2024-01-13T18:08:25.518050Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"torch.float16\n","output_type":"stream"}]},{"cell_type":"code","source":"model_fp16.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_labels_new = []\nall_predictions_new = []","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:09:35.672696Z","iopub.execute_input":"2024-01-13T18:09:35.673104Z","iopub.status.idle":"2024-01-13T18:09:35.678820Z","shell.execute_reply.started":"2024-01-13T18:09:35.673074Z","shell.execute_reply":"2024-01-13T18:09:35.677136Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"correct_new = 0\ntotal_new = 0\nstart_time_fp16 = time()\nwith torch.no_grad():\n    model_fp16.eval()\n    for images, labels in testloader:\n        all_labels_new.extend(labels.numpy())\n        #images, labels = images.to(device), labels.to(device)\n        outputs = model_fp16(images.half())\n        _, predicted = torch.max(outputs.data, 1)\n        total_new += labels.size(0)\n        correct_new += (predicted == labels).sum().item()\n        #predicted_tensor_cpu = predicted.to('cpu')\n        all_predictions_new.extend(predicted.numpy())\nend_time_fp16 = time()\nprint(\"Time: \",end_time_fp16 - start_time_fp16)\n\nprint('Accuracy achieved by the network on test images is: %d%%' % (100 * correct_new / total_new))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_labels_new = np.array(all_labels_new)\nall_predictions_new = np.array(all_predictions_new)\n\n# Calculate the confusion matrix\ncm_fp16 = confusion_matrix(all_labels_new, all_predictions_new)\n\nprint(\"Confusion Matrix:\")\nprint(cm_fp16)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T16:30:31.967940Z","iopub.status.idle":"2024-01-13T16:30:31.968372Z","shell.execute_reply.started":"2024-01-13T16:30:31.968147Z","shell.execute_reply":"2024-01-13T16:30:31.968168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report_new = classification_report(all_labels_new, all_predictions_new)\nprint(report_new)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T16:30:31.970441Z","iopub.status.idle":"2024-01-13T16:30:31.970904Z","shell.execute_reply.started":"2024-01-13T16:30:31.970672Z","shell.execute_reply":"2024-01-13T16:30:31.970694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ===============================================================","metadata":{}},{"cell_type":"code","source":"model_64 = load_checkpoint()\nmodel_64.double()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights_64 = model_64.state_dict()\nprint(weights_64['features.0.weight'].dtype)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:11:29.514654Z","iopub.execute_input":"2024-01-13T18:11:29.515096Z","iopub.status.idle":"2024-01-13T18:11:29.523293Z","shell.execute_reply.started":"2024-01-13T18:11:29.515059Z","shell.execute_reply":"2024-01-13T18:11:29.522104Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"torch.float64\n","output_type":"stream"}]},{"cell_type":"code","source":"all_labels_fp64 = []\nall_predictions_fp64 = []","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:11:32.437627Z","iopub.execute_input":"2024-01-13T18:11:32.438069Z","iopub.status.idle":"2024-01-13T18:11:32.444546Z","shell.execute_reply.started":"2024-01-13T18:11:32.438031Z","shell.execute_reply":"2024-01-13T18:11:32.443041Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"model_64.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct_fp64 = 0\ntotal_fp64 = 0\nstart_time_fp64 = time()\nwith torch.no_grad():\n    model_64.eval()\n    for images, labels in testloader:\n        all_labels_fp64.extend(labels.numpy())\n        #images, labels = images.to(device), labels.to(device)\n        outputs = model_64(images.double())\n        _, predicted = torch.max(outputs.data, 1)\n        total_fp64 += labels.size(0)\n        correct_fp64 += (predicted == labels).sum().item()\n        #predicted_tensor_cpu = predicted.to('cpu')\n        all_predictions_fp64.extend(predicted.numpy())\nend_time_fp64 = time()\nprint(\"Time: \",end_time_fp64 - start_time_fp64)\n\nprint('Accuracy achieved by the network on test images is: %d%%' % (100 * correct_fp64 / total_fp64))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:11:39.979144Z","iopub.execute_input":"2024-01-13T18:11:39.979614Z","iopub.status.idle":"2024-01-13T18:13:57.272254Z","shell.execute_reply.started":"2024-01-13T18:11:39.979576Z","shell.execute_reply":"2024-01-13T18:13:57.270871Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Time:  137.28399443626404\nAccuracy achieved by the network on test images is: 82%\n","output_type":"stream"}]},{"cell_type":"code","source":"all_labels_fp64 = np.array(all_labels_fp64)\nall_predictions_fp64 = np.array(all_predictions_fp64)\n# Calculate the confusion matrix\ncm_fp64 = confusion_matrix(all_labels_fp64, all_predictions_fp64)\nprint(\"Confusion Matrix:\")\nprint(cm_fp64)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:13:57.274915Z","iopub.execute_input":"2024-01-13T18:13:57.276216Z","iopub.status.idle":"2024-01-13T18:13:57.288610Z","shell.execute_reply.started":"2024-01-13T18:13:57.276164Z","shell.execute_reply":"2024-01-13T18:13:57.287632Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Confusion Matrix:\n[[129   6   0   1   1   9   4   0   0   1   0   0   1   0]\n [  4 134   0   0   0   6   4   0   2  18   2   1   0   2]\n [  0   0 193   2   1   0   0  11   0   0   0   4   0   0]\n [  3   4   6 121   5   9   4  27   3   2   1   3   0   2]\n [  3   8   2  22 143   2   2   9   0   0   5   0   6   2]\n [  2   9   0   2   1 145   5   0   1   5   4   1   9   1]\n [  2   9   0   0   2   9 172   2   2   2   0   0   4   0]\n [  0   2   6   7   2   2   1 170   0   0   0   2   1   0]\n [  0   1   1   2   0   2   6   2 178   0   0   0   1   0]\n [  0  29   0   0   0   3   2   0   0 196   1   0   0   0]\n [  0   3   0   0   0  38   1   0   0   2 129   0  17   1]\n [  0   2   7   3   0   0   2   7   0   1   0 171   0   0]\n [  2   2   0   2   5   4   1   0   0   1   2   0 192   0]\n [  1  10   1   2   0   3   7   0   0   2   1   0   4 166]]\n","output_type":"stream"}]},{"cell_type":"code","source":"report_64 = classification_report(all_labels_fp64, all_predictions_fp64)\nprint(report_64)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:13:57.290233Z","iopub.execute_input":"2024-01-13T18:13:57.290638Z","iopub.status.idle":"2024-01-13T18:13:57.314640Z","shell.execute_reply.started":"2024-01-13T18:13:57.290604Z","shell.execute_reply":"2024-01-13T18:13:57.312379Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.88      0.85      0.87       152\n           1       0.61      0.77      0.68       173\n           2       0.89      0.91      0.90       211\n           3       0.74      0.64      0.68       190\n           4       0.89      0.70      0.79       204\n           5       0.62      0.78      0.70       185\n           6       0.82      0.84      0.83       204\n           7       0.75      0.88      0.81       193\n           8       0.96      0.92      0.94       193\n           9       0.85      0.85      0.85       231\n          10       0.89      0.68      0.77       191\n          11       0.94      0.89      0.91       193\n          12       0.82      0.91      0.86       211\n          13       0.95      0.84      0.89       197\n\n    accuracy                           0.82      2728\n   macro avg       0.83      0.82      0.82      2728\nweighted avg       0.83      0.82      0.82      2728\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ===============================================================","metadata":{}},{"cell_type":"code","source":"from torch.ao.quantization import QuantStub, DeQuantStub\nimport torch\nfrom torch.ao.quantization import (\n  get_default_qconfig_mapping,\n  get_default_qat_qconfig_mapping,\n  QConfigMapping,\n)\nimport torch.ao.quantization.quantize_fx as quantize_fx\nimport copy","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:13:57.317153Z","iopub.execute_input":"2024-01-13T18:13:57.317537Z","iopub.status.idle":"2024-01-13T18:13:57.376124Z","shell.execute_reply.started":"2024-01-13T18:13:57.317488Z","shell.execute_reply":"2024-01-13T18:13:57.374972Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"model_fp32 = load_checkpoint()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:13:57.377528Z","iopub.execute_input":"2024-01-13T18:13:57.377934Z","iopub.status.idle":"2024-01-13T18:13:58.344016Z","shell.execute_reply.started":"2024-01-13T18:13:57.377900Z","shell.execute_reply":"2024-01-13T18:13:58.342710Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"model_fp32.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:13:58.345842Z","iopub.execute_input":"2024-01-13T18:13:58.346309Z","iopub.status.idle":"2024-01-13T18:13:58.357692Z","shell.execute_reply.started":"2024-01-13T18:13:58.346266Z","shell.execute_reply":"2024-01-13T18:13:58.356256Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n    (relu1): ReLU()\n    (dropout1): Dropout(p=0.5, inplace=False)\n    (fc2): Linear(in_features=4096, out_features=14, bias=True)\n    (output): LogSoftmax(dim=1)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"input_data = next(iter(trainloader))[0][:1]  \ncalibrate_data = input_data.to(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:13:58.359438Z","iopub.execute_input":"2024-01-13T18:13:58.359953Z","iopub.status.idle":"2024-01-13T18:13:58.621279Z","shell.execute_reply.started":"2024-01-13T18:13:58.359908Z","shell.execute_reply":"2024-01-13T18:13:58.620413Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"model_int8 = copy.deepcopy(model_fp32)\n#model_int8.to(device)\nqconfig_mapping = get_default_qconfig_mapping(\"qnnpack\")\nmodel_int8.eval()\n# prepare\nmodel_prepared = quantize_fx.prepare_fx(model_int8, qconfig_mapping, calibrate_data)\n# calibrate ","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:13:58.622837Z","iopub.execute_input":"2024-01-13T18:13:58.623987Z","iopub.status.idle":"2024-01-13T18:13:58.808866Z","shell.execute_reply.started":"2024-01-13T18:13:58.623941Z","shell.execute_reply":"2024-01-13T18:13:58.807683Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    for i in range(20):\n        batch = next(iter(trainloader))[0]\n        output = model_prepared(batch.to('cpu'))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:13:58.811543Z","iopub.execute_input":"2024-01-13T18:13:58.812687Z","iopub.status.idle":"2024-01-13T18:14:28.010917Z","shell.execute_reply.started":"2024-01-13T18:13:58.812638Z","shell.execute_reply":"2024-01-13T18:14:28.010011Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"model_quantized_static = quantize_fx.convert_fx(model_prepared)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:14:28.015142Z","iopub.execute_input":"2024-01-13T18:14:28.016520Z","iopub.status.idle":"2024-01-13T18:14:29.616291Z","shell.execute_reply.started":"2024-01-13T18:14:28.016450Z","shell.execute_reply":"2024-01-13T18:14:29.615242Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"model_quantized_static.state_dict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_quantized_static","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:14:30.200764Z","iopub.execute_input":"2024-01-13T18:14:30.201067Z","iopub.status.idle":"2024-01-13T18:14:30.633086Z","shell.execute_reply.started":"2024-01-13T18:14:30.201040Z","shell.execute_reply":"2024-01-13T18:14:30.631864Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"GraphModule(\n  (features): Module(\n    (0): QuantizedConvReLU2d(3, 64, kernel_size=(11, 11), stride=(4, 4), scale=0.09054233878850937, zero_point=0, padding=(2, 2))\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): QuantizedConvReLU2d(64, 192, kernel_size=(5, 5), stride=(1, 1), scale=0.19043809175491333, zero_point=0, padding=(2, 2))\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): QuantizedConvReLU2d(192, 384, kernel_size=(3, 3), stride=(1, 1), scale=0.13451653718948364, zero_point=0, padding=(1, 1))\n    (8): QuantizedConvReLU2d(384, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.1333240419626236, zero_point=0, padding=(1, 1))\n    (10): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08818456530570984, zero_point=0, padding=(1, 1))\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Module(\n    (fc1): QuantizedLinearReLU(in_features=9216, out_features=4096, scale=0.3145882189273834, zero_point=0, qscheme=torch.per_tensor_affine)\n    (dropout1): QuantizedDropout(p=0.5, inplace=False)\n    (fc2): QuantizedLinear(in_features=4096, out_features=14, scale=0.3183004558086395, zero_point=94, qscheme=torch.per_tensor_affine)\n    (output): LogSoftmax(dim=1)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"all_labels_int8 = []\nall_predictions_int8 = []","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:14:30.634326Z","iopub.execute_input":"2024-01-13T18:14:30.634730Z","iopub.status.idle":"2024-01-13T18:14:30.640755Z","shell.execute_reply.started":"2024-01-13T18:14:30.634695Z","shell.execute_reply":"2024-01-13T18:14:30.639556Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"model_quantized_static.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:14:30.642292Z","iopub.execute_input":"2024-01-13T18:14:30.643452Z","iopub.status.idle":"2024-01-13T18:14:31.075287Z","shell.execute_reply.started":"2024-01-13T18:14:30.643416Z","shell.execute_reply":"2024-01-13T18:14:31.074046Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"GraphModule(\n  (features): Module(\n    (0): QuantizedConvReLU2d(3, 64, kernel_size=(11, 11), stride=(4, 4), scale=0.09054233878850937, zero_point=0, padding=(2, 2))\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): QuantizedConvReLU2d(64, 192, kernel_size=(5, 5), stride=(1, 1), scale=0.19043809175491333, zero_point=0, padding=(2, 2))\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): QuantizedConvReLU2d(192, 384, kernel_size=(3, 3), stride=(1, 1), scale=0.13451653718948364, zero_point=0, padding=(1, 1))\n    (8): QuantizedConvReLU2d(384, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.1333240419626236, zero_point=0, padding=(1, 1))\n    (10): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08818456530570984, zero_point=0, padding=(1, 1))\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Module(\n    (fc1): QuantizedLinearReLU(in_features=9216, out_features=4096, scale=0.3145882189273834, zero_point=0, qscheme=torch.per_tensor_affine)\n    (dropout1): QuantizedDropout(p=0.5, inplace=False)\n    (fc2): QuantizedLinear(in_features=4096, out_features=14, scale=0.3183004558086395, zero_point=94, qscheme=torch.per_tensor_affine)\n    (output): LogSoftmax(dim=1)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"correct_pred = 0\ntotal_pred = 0\nstart_time_int8 = time()\nwith torch.no_grad():\n    model_quantized_static.eval()\n    for data in testloader:\n        images, labels = data\n        all_labels_int8.extend(labels.numpy())\n        #images, labels = images.to(device), labels.to(device)\n        outputs = model_quantized_static(images.to('cpu'))\n        _, predicted = torch.max(outputs.data, 1)\n        total_pred += labels.size(0)\n        correct_pred += (predicted == labels).sum().item()\n        predicted_tensor_cpu = predicted.to('cpu')\n        all_predictions_int8.extend(predicted_tensor_cpu.numpy())\nend_time_int8 = time()\nprint(\"Time: \",end_time_int8 - start_time_int8)\n\nprint('Accuracy achieved by the network on test images is: %d%%' % (100 * correct_pred / total_pred))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:14:31.077595Z","iopub.execute_input":"2024-01-13T18:14:31.078434Z","iopub.status.idle":"2024-01-13T18:15:05.219959Z","shell.execute_reply.started":"2024-01-13T18:14:31.078386Z","shell.execute_reply":"2024-01-13T18:15:05.219016Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Time:  34.13240170478821\nAccuracy achieved by the network on test images is: 81%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-01-13T16:59:23.733335Z","iopub.execute_input":"2024-01-13T16:59:23.734045Z","iopub.status.idle":"2024-01-13T16:59:23.739769Z","shell.execute_reply.started":"2024-01-13T16:59:23.734007Z","shell.execute_reply":"2024-01-13T16:59:23.738872Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:19:08.133824Z","iopub.execute_input":"2024-01-13T18:19:08.134457Z","iopub.status.idle":"2024-01-13T18:19:08.140837Z","shell.execute_reply.started":"2024-01-13T18:19:08.134405Z","shell.execute_reply":"2024-01-13T18:19:08.139461Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"def print_model_size(mdl):\n    torch.save(mdl.state_dict(), \"tmp.pt\")\n    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n    os.remove('tmp.pt')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:17:26.026802Z","iopub.execute_input":"2024-01-13T18:17:26.027224Z","iopub.status.idle":"2024-01-13T18:17:26.033894Z","shell.execute_reply.started":"2024-01-13T18:17:26.027190Z","shell.execute_reply":"2024-01-13T18:17:26.032701Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"print(\"FP64 model size:\",end='')\nprint_model_size(model_64)\nprint(\"FP32 model size:\",end='')\nprint_model_size(model)\nprint(\"FP16 model size:\",end='')\nprint_model_size(model_fp16)\nprint(\"INT8 model size:\",end='')\nprint_model_size(model_quantized_static)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:19:54.979603Z","iopub.execute_input":"2024-01-13T18:19:54.979999Z","iopub.status.idle":"2024-01-13T18:19:56.273247Z","shell.execute_reply.started":"2024-01-13T18:19:54.979967Z","shell.execute_reply":"2024-01-13T18:19:56.272005Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"FP64 model size:322.24 MB\nFP32 model size:161.12 MB\nFP16 model size:80.56 MB\nINT8 model size:40.30 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"all_labels_int8 = np.array(all_labels_int8)\nall_predictions_int8 = np.array(all_predictions_int8)\n\n# Calculate the confusion matrix\ncm_int8 = confusion_matrix(all_labels_int8, all_predictions_int8)\n\nprint(\"Confusion Matrix:\")\nprint(cm_int8)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T16:30:32.003557Z","iopub.status.idle":"2024-01-13T16:30:32.003937Z","shell.execute_reply.started":"2024-01-13T16:30:32.003770Z","shell.execute_reply":"2024-01-13T16:30:32.003787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report_int8 = classification_report(all_labels_int8, all_predictions_int8)\nprint(report_int8)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T16:30:32.004905Z","iopub.status.idle":"2024-01-13T16:30:32.005232Z","shell.execute_reply.started":"2024-01-13T16:30:32.005070Z","shell.execute_reply":"2024-01-13T16:30:32.005086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, child in model_int8.named_children():\n        for x, y in child.named_children():\n            print(name,x)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T16:30:32.006410Z","iopub.status.idle":"2024-01-13T16:30:32.006779Z","shell.execute_reply.started":"2024-01-13T16:30:32.006610Z","shell.execute_reply":"2024-01-13T16:30:32.006631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for module in model_int8.modules():\n    classname = module.__class__.__name__\n    print(classname)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T16:30:32.008513Z","iopub.status.idle":"2024-01-13T16:30:32.008869Z","shell.execute_reply.started":"2024-01-13T16:30:32.008703Z","shell.execute_reply":"2024-01-13T16:30:32.008720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for module in model_int8.modules():\n    classname = module.__class__.__name__   \n    if 'LogSoftmax' == classname:\n        module = nn.Sequential(OrderedDict([\n                          ('dequant',torch.quantization.DeQuantStub()),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T16:30:32.010454Z","iopub.status.idle":"2024-01-13T16:30:32.010802Z","shell.execute_reply.started":"2024-01-13T16:30:32.010639Z","shell.execute_reply":"2024-01-13T16:30:32.010655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_int8","metadata":{"execution":{"iopub.status.busy":"2024-01-13T16:30:32.012376Z","iopub.status.idle":"2024-01-13T16:30:32.012747Z","shell.execute_reply.started":"2024-01-13T16:30:32.012553Z","shell.execute_reply":"2024-01-13T16:30:32.012583Z"},"trusted":true},"execution_count":null,"outputs":[]}]}