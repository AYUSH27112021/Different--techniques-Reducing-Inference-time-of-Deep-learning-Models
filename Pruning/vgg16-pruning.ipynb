{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6810129,"sourceType":"datasetVersion","datasetId":3917752}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports here\nimport torch\nimport PIL\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom torchvision import datasets, transforms, models\nfrom torch import nn\nfrom torch import optim\nfrom collections import OrderedDict\nfrom time import time\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport numpy as np\nimport skimage.io as io\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:01.296032Z","iopub.execute_input":"2024-10-01T07:19:01.296324Z","iopub.status.idle":"2024-10-01T07:19:09.763545Z","shell.execute_reply.started":"2024-10-01T07:19:01.296297Z","shell.execute_reply":"2024-10-01T07:19:09.762776Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/flower-classification'\ntrain_dir = data_dir + '/train'\n\n# Define your transformations\ntrain_transforms = transforms.Compose([\n    transforms.RandomRotation(30),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Load all the images from the train folder\nall_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n\n# Calculate the sizes for train, validation, and test sets\ntotal_size = len(all_data)\ntrain_size = int(0.7 * total_size)\ntest_size = int(0.2 * total_size)\nvalid_size = total_size - train_size - test_size\n\n# Use random_split to split the dataset\ntrain_data, valid_data, test_data = torch.utils.data.random_split(all_data, [train_size, valid_size, test_size])\n\n# Create data loaders\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size=50, shuffle=False)\nvalidloader = torch.utils.data.DataLoader(valid_data, batch_size=50)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=50)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:09.765008Z","iopub.execute_input":"2024-10-01T07:19:09.765432Z","iopub.status.idle":"2024-10-01T07:19:13.816643Z","shell.execute_reply.started":"2024-10-01T07:19:09.765407Z","shell.execute_reply":"2024-10-01T07:19:13.815832Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load a pre-trained network \nmodel = models.vgg16(pretrained=True)\nmodel.name = \"vgg16\"\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:13.817641Z","iopub.execute_input":"2024-10-01T07:19:13.817894Z","iopub.status.idle":"2024-10-01T07:19:19.006698Z","shell.execute_reply.started":"2024-10-01T07:19:13.817872Z","shell.execute_reply":"2024-10-01T07:19:19.005665Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:03<00:00, 162MB/s]  \n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:19.008693Z","iopub.execute_input":"2024-10-01T07:19:19.009069Z","iopub.status.idle":"2024-10-01T07:19:19.013689Z","shell.execute_reply.started":"2024-10-01T07:19:19.009042Z","shell.execute_reply":"2024-10-01T07:19:19.012725Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"classifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(25088, 4096, bias=True)),\n                          ('relu1', nn.ReLU()),\n                          ('dropout1', nn.Dropout(p=0.5)),\n                          ('fc2', nn.Linear(4096, 14, bias=True)),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))\n    \nmodel.classifier = classifier","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:19.015003Z","iopub.execute_input":"2024-10-01T07:19:19.015343Z","iopub.status.idle":"2024-10-01T07:19:20.157405Z","shell.execute_reply.started":"2024-10-01T07:19:19.015311Z","shell.execute_reply":"2024-10-01T07:19:20.156640Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:20.158838Z","iopub.execute_input":"2024-10-01T07:19:20.159372Z","iopub.status.idle":"2024-10-01T07:19:20.218252Z","shell.execute_reply.started":"2024-10-01T07:19:20.159335Z","shell.execute_reply":"2024-10-01T07:19:20.217313Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:20.219364Z","iopub.execute_input":"2024-10-01T07:19:20.219658Z","iopub.status.idle":"2024-10-01T07:19:20.536876Z","shell.execute_reply.started":"2024-10-01T07:19:20.219633Z","shell.execute_reply":"2024-10-01T07:19:20.535890Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n    (relu1): ReLU()\n    (dropout1): Dropout(p=0.5, inplace=False)\n    (fc2): Linear(in_features=4096, out_features=14, bias=True)\n    (output): LogSoftmax(dim=1)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Define loss and optimizer\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n\nepochs = 5\nprint_every = 30 # Prints every 30 images out of batch of 50 images\nsteps = 0","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:20.537883Z","iopub.execute_input":"2024-10-01T07:19:20.538178Z","iopub.status.idle":"2024-10-01T07:19:20.543288Z","shell.execute_reply.started":"2024-10-01T07:19:20.538153Z","shell.execute_reply":"2024-10-01T07:19:20.542397Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def validation(model, testloader, criterion):\n    test_loss = 0\n    accuracy = 0\n    \n    for ii, (inputs, labels) in enumerate(testloader):\n        \n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        output = model.forward(inputs)\n        test_loss += criterion(output, labels).item()\n        \n        ps = torch.exp(output)\n        equality = (labels.data == ps.max(dim=1)[1])\n        accuracy += equality.type(torch.FloatTensor).mean()\n    \n    return test_loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:20.544318Z","iopub.execute_input":"2024-10-01T07:19:20.544569Z","iopub.status.idle":"2024-10-01T07:19:20.552770Z","shell.execute_reply.started":"2024-10-01T07:19:20.544547Z","shell.execute_reply":"2024-10-01T07:19:20.551964Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:20.556311Z","iopub.execute_input":"2024-10-01T07:19:20.556633Z","iopub.status.idle":"2024-10-01T07:19:20.563181Z","shell.execute_reply.started":"2024-10-01T07:19:20.556609Z","shell.execute_reply":"2024-10-01T07:19:20.562275Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n    (relu1): ReLU()\n    (dropout1): Dropout(p=0.5, inplace=False)\n    (fc2): Linear(in_features=4096, out_features=14, bias=True)\n    (output): LogSoftmax(dim=1)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_1(model,steps,print_every,epochs):\n    print(\"Training process initializing .....\\n\")\n\n    for e in range(epochs):\n        running_loss = 0\n        model.train() # Technically not necessary, setting this for good measure\n\n        for ii, (inputs, labels) in enumerate(trainloader):\n            steps += 1\n\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n\n            # Forward and backward passes\n            outputs = model.forward(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n            if steps % print_every == 0:\n                model.eval()\n\n                with torch.no_grad():\n                    valid_loss, accuracy = validation(model, validloader, criterion)\n\n                print(\"Epoch: {}/{} | \".format(e+1, epochs),\n                      \"Training Loss: {:.4f} | \".format(running_loss/print_every),\n                      \"Validation Loss: {:.4f} | \".format(valid_loss/len(validloader)),\n                      \"Validation Accuracy: {:.4f}\".format(accuracy/len(validloader)))\n\n                running_loss = 0\n                model.train()\n\n    print(\"\\nTraining process is now complete!!\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:20.564251Z","iopub.execute_input":"2024-10-01T07:19:20.564526Z","iopub.status.idle":"2024-10-01T07:19:20.573791Z","shell.execute_reply.started":"2024-10-01T07:19:20.564492Z","shell.execute_reply":"2024-10-01T07:19:20.572995Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# original_dataset = train_data.dataset\n# # Create a class_to_idx mapping\n# model.class_to_idx = {class_name: idx for idx, class_name in enumerate(original_dataset.classes)}\n# checkpoint = {'architecture': model.name,\n#              'classifier': model.classifier,\n#              'class_to_idx': model.class_to_idx,\n#              'state_dict': model.state_dict()}\n\n# torch.save(checkpoint, 'model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:20.575004Z","iopub.execute_input":"2024-10-01T07:19:20.575402Z","iopub.status.idle":"2024-10-01T07:19:20.585916Z","shell.execute_reply.started":"2024-10-01T07:19:20.575377Z","shell.execute_reply":"2024-10-01T07:19:20.585225Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.utils.prune as prune\n#     for name, module in model.named_modules():\n#         if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n#             prune.l1_unstructured(module, name='weight', amount=0.5) \n#     #         prune.remove(module, name='weight')\n#     # Define a dictionary to store the model information\n#     # checkpoint = {\n#     #     'architecture': model.name,\n#     #     'classifier': model.classifier,\n#     #     'class_to_idx': {class_name: idx for idx, class_name in enumerate(train_data.dataset.classes)},\n#     #     'state_dict': model.state_dict()\n#     # }\n\n#     # # Save the checkpoint dictionary to a file\n#     # torch.save(checkpoint, 'pruned_model_1.pth')\n#     for name, module in model.named_modules():\n#         if isinstance(module, torch.nn.Conv2d):\n#             prune.l1_unstructured(module, name='weight', amount=0.2) \n#     #         prune.remove(module, name='weight')\n#         elif isinstance(module, torch.nn.Linear):\n#             prune.l1_unstructured(module, name='weight', amount=0.4) \n        ","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:20.586901Z","iopub.execute_input":"2024-10-01T07:19:20.587241Z","iopub.status.idle":"2024-10-01T07:19:20.596373Z","shell.execute_reply.started":"2024-10-01T07:19:20.587199Z","shell.execute_reply":"2024-10-01T07:19:20.595616Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def global_prune(model):\n    classifier_size = len(model.classifier)\n    parameters_to_prune = [\n        (model.features[0], 'weight'),  # First convolutional layer\n        (model.features[2], 'weight'),  # Second convolutional layer\n        (model.features[5], 'weight'),  # Third convolutional layer\n        (model.features[7], 'weight'),  # Fourth convolutional layer\n        (model.features[10], 'weight'),  # Fifth convolutional layer\n        (model.features[12], 'weight'),  # Sixth convolutional layer\n        (model.features[14], 'weight'),  # Seventh convolutional layer\n        (model.features[17], 'weight'),  # Eighth convolutional layer\n        (model.features[19], 'weight'),  # Ninth convolutional layer\n        (model.features[21], 'weight'),  # Tenth convolutional layer\n        (model.features[24], 'weight'),  # Eleventh convolutional layer\n        (model.features[26], 'weight'),  # Twelfth convolutional layer\n        (model.features[28], 'weight'),  # Thirteenth convolutional layer\n    ]\n    for module in model.features:\n        if isinstance(module, torch.nn.Conv2d):\n            parameters_to_prune.append((module, 'weight'))\n\n    # Add fully connected layers to parameters_to_prune\n    for module in model.classifier:\n        if isinstance(module, torch.nn.Linear):\n            parameters_to_prune.append((module, 'weight'))\n    # Apply global unstructured pruning\n    prune.global_unstructured(\n        parameters_to_prune,\n        pruning_method=prune.L1Unstructured,\n        amount=0.4,  \n    )\n    for name, module in model.named_modules():\n        if isinstance(module, torch.nn.Conv2d):\n            prune.remove(module, name='weight')\n        elif isinstance(module, torch.nn.Linear):\n            prune.remove(module, name='weight') \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:20.597273Z","iopub.execute_input":"2024-10-01T07:19:20.597516Z","iopub.status.idle":"2024-10-01T07:19:20.608495Z","shell.execute_reply.started":"2024-10-01T07:19:20.597494Z","shell.execute_reply":"2024-10-01T07:19:20.607600Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def prune_1(model):\n    for name, module in model.named_modules():\n        if isinstance(module, torch.nn.Conv2d):\n            prune.l1_unstructured(module, name='weight', amount=0.5) \n        elif isinstance(module, torch.nn.Linear):\n            prune.l1_unstructured(module, name='weight', amount=0.5) \n    for name, module in model.named_modules():\n        if isinstance(module, torch.nn.Conv2d):\n            prune.remove(module, name='weight')\n        elif isinstance(module, torch.nn.Linear):\n             prune.remove(module, name='weight') \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:20.609578Z","iopub.execute_input":"2024-10-01T07:19:20.610231Z","iopub.status.idle":"2024-10-01T07:19:20.622164Z","shell.execute_reply.started":"2024-10-01T07:19:20.610200Z","shell.execute_reply":"2024-10-01T07:19:20.621287Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def print_sparsity(model):\n    for name, module in model.named_modules():\n        if isinstance(module, torch.nn.Conv2d):\n                print(\"Sparsity in conv .weight: {:.2f}%\".format(100. * float(torch.sum(module.weight == 0))/ float(module.weight.nelement())))\n\n        elif isinstance(module, torch.nn.Linear):\n            print(\"Sparsity in conv .weight: {:.2f}%\".format(100. * float(torch.sum(module.weight == 0))/ float(module.weight.nelement())))","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:20.623558Z","iopub.execute_input":"2024-10-01T07:19:20.623885Z","iopub.status.idle":"2024-10-01T07:19:20.635033Z","shell.execute_reply.started":"2024-10-01T07:19:20.623855Z","shell.execute_reply":"2024-10-01T07:19:20.634199Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"for i in range(2):\n    model=train_1(model,steps,print_every,epochs)\n    model=prune_1(model)\n    print_sparsity(model)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:19:20.636073Z","iopub.execute_input":"2024-10-01T07:19:20.636362Z","iopub.status.idle":"2024-10-01T07:48:17.397159Z","shell.execute_reply.started":"2024-10-01T07:19:20.636339Z","shell.execute_reply":"2024-10-01T07:48:17.396176Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Training process initializing .....\n\nEpoch: 1/5 |  Training Loss: 3.1476 |  Validation Loss: 1.1028 |  Validation Accuracy: 0.6567\nEpoch: 1/5 |  Training Loss: 1.0908 |  Validation Loss: 0.7928 |  Validation Accuracy: 0.7486\nEpoch: 1/5 |  Training Loss: 0.9501 |  Validation Loss: 0.6993 |  Validation Accuracy: 0.7655\nEpoch: 1/5 |  Training Loss: 0.8544 |  Validation Loss: 0.7963 |  Validation Accuracy: 0.7440\nEpoch: 1/5 |  Training Loss: 0.8626 |  Validation Loss: 0.7377 |  Validation Accuracy: 0.7793\nEpoch: 1/5 |  Training Loss: 0.8680 |  Validation Loss: 0.6895 |  Validation Accuracy: 0.7736\nEpoch: 2/5 |  Training Loss: 0.5085 |  Validation Loss: 0.7167 |  Validation Accuracy: 0.7833\nEpoch: 2/5 |  Training Loss: 0.8759 |  Validation Loss: 0.6619 |  Validation Accuracy: 0.8083\nEpoch: 2/5 |  Training Loss: 0.8254 |  Validation Loss: 0.6734 |  Validation Accuracy: 0.7840\nEpoch: 2/5 |  Training Loss: 0.8188 |  Validation Loss: 0.7524 |  Validation Accuracy: 0.7714\nEpoch: 2/5 |  Training Loss: 0.7571 |  Validation Loss: 0.6539 |  Validation Accuracy: 0.7912\nEpoch: 2/5 |  Training Loss: 0.7114 |  Validation Loss: 0.5932 |  Validation Accuracy: 0.8083\nEpoch: 3/5 |  Training Loss: 0.2041 |  Validation Loss: 0.5852 |  Validation Accuracy: 0.8129\nEpoch: 3/5 |  Training Loss: 0.7193 |  Validation Loss: 0.5753 |  Validation Accuracy: 0.8126\nEpoch: 3/5 |  Training Loss: 0.7210 |  Validation Loss: 0.5550 |  Validation Accuracy: 0.8288\nEpoch: 3/5 |  Training Loss: 0.7395 |  Validation Loss: 0.5927 |  Validation Accuracy: 0.8107\nEpoch: 3/5 |  Training Loss: 0.6457 |  Validation Loss: 0.5468 |  Validation Accuracy: 0.8124\nEpoch: 3/5 |  Training Loss: 0.6500 |  Validation Loss: 0.6336 |  Validation Accuracy: 0.8043\nEpoch: 3/5 |  Training Loss: 0.7631 |  Validation Loss: 0.6367 |  Validation Accuracy: 0.8033\nEpoch: 4/5 |  Training Loss: 0.6622 |  Validation Loss: 0.5503 |  Validation Accuracy: 0.8193\nEpoch: 4/5 |  Training Loss: 0.7226 |  Validation Loss: 0.5354 |  Validation Accuracy: 0.8321\nEpoch: 4/5 |  Training Loss: 0.7687 |  Validation Loss: 0.6121 |  Validation Accuracy: 0.8174\nEpoch: 4/5 |  Training Loss: 0.6911 |  Validation Loss: 0.5288 |  Validation Accuracy: 0.8443\nEpoch: 4/5 |  Training Loss: 0.6619 |  Validation Loss: 0.6067 |  Validation Accuracy: 0.8052\nEpoch: 4/5 |  Training Loss: 0.7120 |  Validation Loss: 0.6042 |  Validation Accuracy: 0.8038\nEpoch: 5/5 |  Training Loss: 0.3636 |  Validation Loss: 0.5851 |  Validation Accuracy: 0.8214\nEpoch: 5/5 |  Training Loss: 0.7320 |  Validation Loss: 0.5807 |  Validation Accuracy: 0.8124\nEpoch: 5/5 |  Training Loss: 0.7130 |  Validation Loss: 0.5211 |  Validation Accuracy: 0.8362\nEpoch: 5/5 |  Training Loss: 0.6721 |  Validation Loss: 0.5373 |  Validation Accuracy: 0.8305\nEpoch: 5/5 |  Training Loss: 0.7166 |  Validation Loss: 0.6150 |  Validation Accuracy: 0.8071\nEpoch: 5/5 |  Training Loss: 0.6142 |  Validation Loss: 0.5433 |  Validation Accuracy: 0.8248\n\nTraining process is now complete!!\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nTraining process initializing .....\n\nEpoch: 1/5 |  Training Loss: 0.9767 |  Validation Loss: 0.7477 |  Validation Accuracy: 0.7671\nEpoch: 1/5 |  Training Loss: 0.9538 |  Validation Loss: 0.7369 |  Validation Accuracy: 0.7674\nEpoch: 1/5 |  Training Loss: 0.9722 |  Validation Loss: 0.7091 |  Validation Accuracy: 0.7702\nEpoch: 1/5 |  Training Loss: 0.9130 |  Validation Loss: 0.7241 |  Validation Accuracy: 0.7655\nEpoch: 1/5 |  Training Loss: 0.8948 |  Validation Loss: 0.7319 |  Validation Accuracy: 0.7683\nEpoch: 1/5 |  Training Loss: 0.8704 |  Validation Loss: 0.6385 |  Validation Accuracy: 0.7838\nEpoch: 2/5 |  Training Loss: 0.5362 |  Validation Loss: 0.6510 |  Validation Accuracy: 0.7864\nEpoch: 2/5 |  Training Loss: 0.8797 |  Validation Loss: 0.6678 |  Validation Accuracy: 0.7760\nEpoch: 2/5 |  Training Loss: 0.8863 |  Validation Loss: 0.6644 |  Validation Accuracy: 0.7819\nEpoch: 2/5 |  Training Loss: 0.7985 |  Validation Loss: 0.6462 |  Validation Accuracy: 0.7855\nEpoch: 2/5 |  Training Loss: 0.8326 |  Validation Loss: 0.6227 |  Validation Accuracy: 0.7905\nEpoch: 2/5 |  Training Loss: 0.7728 |  Validation Loss: 0.6655 |  Validation Accuracy: 0.7886\nEpoch: 3/5 |  Training Loss: 0.2092 |  Validation Loss: 0.6061 |  Validation Accuracy: 0.8057\nEpoch: 3/5 |  Training Loss: 0.8043 |  Validation Loss: 0.6886 |  Validation Accuracy: 0.7829\nEpoch: 3/5 |  Training Loss: 0.8068 |  Validation Loss: 0.6239 |  Validation Accuracy: 0.8010\nEpoch: 3/5 |  Training Loss: 0.7987 |  Validation Loss: 0.6224 |  Validation Accuracy: 0.7943\nEpoch: 3/5 |  Training Loss: 0.8076 |  Validation Loss: 0.6698 |  Validation Accuracy: 0.7931\nEpoch: 3/5 |  Training Loss: 0.7700 |  Validation Loss: 0.6275 |  Validation Accuracy: 0.7971\nEpoch: 3/5 |  Training Loss: 0.7969 |  Validation Loss: 0.6319 |  Validation Accuracy: 0.7993\nEpoch: 4/5 |  Training Loss: 0.7642 |  Validation Loss: 0.6500 |  Validation Accuracy: 0.7845\nEpoch: 4/5 |  Training Loss: 0.7838 |  Validation Loss: 0.6012 |  Validation Accuracy: 0.8064\nEpoch: 4/5 |  Training Loss: 0.8177 |  Validation Loss: 0.6290 |  Validation Accuracy: 0.8131\nEpoch: 4/5 |  Training Loss: 0.8021 |  Validation Loss: 0.6081 |  Validation Accuracy: 0.8171\nEpoch: 4/5 |  Training Loss: 0.7250 |  Validation Loss: 0.5973 |  Validation Accuracy: 0.8133\nEpoch: 4/5 |  Training Loss: 0.7294 |  Validation Loss: 0.5699 |  Validation Accuracy: 0.8055\nEpoch: 5/5 |  Training Loss: 0.3970 |  Validation Loss: 0.6102 |  Validation Accuracy: 0.8029\nEpoch: 5/5 |  Training Loss: 0.7346 |  Validation Loss: 0.5783 |  Validation Accuracy: 0.8114\nEpoch: 5/5 |  Training Loss: 0.7782 |  Validation Loss: 0.5811 |  Validation Accuracy: 0.8226\nEpoch: 5/5 |  Training Loss: 0.7642 |  Validation Loss: 0.5868 |  Validation Accuracy: 0.8055\nEpoch: 5/5 |  Training Loss: 0.7588 |  Validation Loss: 0.6141 |  Validation Accuracy: 0.8033\nEpoch: 5/5 |  Training Loss: 0.7823 |  Validation Loss: 0.5859 |  Validation Accuracy: 0.8081\n\nTraining process is now complete!!\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\nSparsity in conv .weight: 50.00%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ndef print_model_size(mdl):\n    torch.save(mdl.state_dict(), \"tmp.pt\")\n    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n    os.remove('tmp.pt')\n\nprint_model_size(model)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:17.398446Z","iopub.execute_input":"2024-10-01T07:48:17.399168Z","iopub.status.idle":"2024-10-01T07:48:18.367225Z","shell.execute_reply.started":"2024-10-01T07:48:17.399130Z","shell.execute_reply":"2024-10-01T07:48:18.366301Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"470.16 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"for name, module in model.named_modules():\n    if isinstance(module, torch.nn.Conv2d):\n        prune.remove(module, name='weight')\n    elif isinstance(module, torch.nn.Linear):\n        prune.remove(module, name='weight') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(\"Sparsity in conv .weight: {:.2f}%\".format(100. * float(torch.sum(module.weight == 0))/ float(module.weight.nelement())))","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.862617Z","iopub.status.idle":"2024-10-01T07:48:18.863174Z","shell.execute_reply.started":"2024-10-01T07:48:18.862891Z","shell.execute_reply":"2024-10-01T07:48:18.862911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ndef print_model_size(mdl):\n    torch.save(mdl.state_dict(), \"tmp.pt\")\n    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n    os.remove('tmp.pt')\n\nprint_model_size(model)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.865272Z","iopub.status.idle":"2024-10-01T07:48:18.865973Z","shell.execute_reply.started":"2024-10-01T07:48:18.865693Z","shell.execute_reply":"2024-10-01T07:48:18.865714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred(Model,Testloader):\n    all_labels = []\n    all_predictions = []\n    correct = 0\n    total = 0\n    start_time = time()\n    with torch.no_grad():\n        Model.eval()\n        for images, labels in Testloader:\n            all_labels.extend(labels.numpy())\n            images, labels = images.to(device), labels.to(device)\n            outputs = Model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            predicted_tensor_cpu = predicted.to('cpu')\n            all_predictions.extend(predicted_tensor_cpu.numpy())\n    end_time = time()\n    print(\"Time: \",end_time - start_time)\n    print('Accuracy achieved by the network on test images is: %d%%' % (100 * correct / total))\n    \n    return all_labels,all_predictions","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.867107Z","iopub.status.idle":"2024-10-01T07:48:18.867556Z","shell.execute_reply.started":"2024-10-01T07:48:18.867322Z","shell.execute_reply":"2024-10-01T07:48:18.867340Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_fp32,predictions_fp32 = pred(model,testloader)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.869133Z","iopub.status.idle":"2024-10-01T07:48:18.869567Z","shell.execute_reply.started":"2024-10-01T07:48:18.869338Z","shell.execute_reply":"2024-10-01T07:48:18.869357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, module in model.named_modules():\n    if isinstance(module, torch.nn.Conv2d):\n            print(\"Sparsity in conv{:.2f} .weight: {:.2f}%\".format(n,100. * float(torch.sum(module.weight == 0))/ float(module.weight.nelement())))\n            \n    elif isinstance(module, torch.nn.Linear):\n        print(\"Sparsity in conv{:.2f} .weight: {:.2f}%\".format(n,100. * float(torch.sum(module.weight == 0))/ float(module.weight.nelement())))","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.871137Z","iopub.status.idle":"2024-10-01T07:48:18.871480Z","shell.execute_reply.started":"2024-10-01T07:48:18.871309Z","shell.execute_reply":"2024-10-01T07:48:18.871323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nall_labels = np.array(labels_fp32)\nall_predictions = np.array(predictions_fp32)\n# Calculate the confusion matrix\ncm = confusion_matrix(labels_fp32, predictions_fp32)\nprint(\"Confusion Matrix:\")\nprint(cm)\nprint('----------------------------------------------------------------')\nprint(\"Classification Report:\")\nreport = classification_report(all_labels, all_predictions)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.873614Z","iopub.status.idle":"2024-10-01T07:48:18.874071Z","shell.execute_reply.started":"2024-10-01T07:48:18.873826Z","shell.execute_reply":"2024-10-01T07:48:18.873844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_dataset = train_data.dataset\n# Create a class_to_idx mapping\nmodel.class_to_idx = {class_name: idx for idx, class_name in enumerate(original_dataset.classes)}\ncheckpoint = {'architecture': model.name,\n             'classifier': model.classifier,\n             'class_to_idx': model.class_to_idx,\n             'state_dict': model.state_dict()}\n\ntorch.save(checkpoint, 'model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.875225Z","iopub.status.idle":"2024-10-01T07:48:18.875664Z","shell.execute_reply.started":"2024-10-01T07:48:18.875433Z","shell.execute_reply":"2024-10-01T07:48:18.875452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_checkpoint():\n    \"\"\"\n    Loads deep learning model checkpoint.\n    \"\"\"\n    \n    # Load the saved file\n    checkpoint = torch.load(\"/kaggle/input/models/model_vgg16.pth\") # path to model\n    \n    # Download pretrained model\n    model = models.vgg16(pretrained=True);\n    \n    # Freeze parameters so we don't backprop through them\n    for param in model.parameters(): param.requires_grad = False\n    \n    # Load stuff from checkpoint\n    model.class_to_idx = checkpoint['class_to_idx']\n    model.classifier = checkpoint['classifier']\n    model.load_state_dict(checkpoint['state_dict'])\n\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.876808Z","iopub.status.idle":"2024-10-01T07:48:18.877509Z","shell.execute_reply.started":"2024-10-01T07:48:18.877245Z","shell.execute_reply":"2024-10-01T07:48:18.877277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_checkpoint():\n    \"\"\"\n    Loads deep learning model checkpoint.\n    \"\"\"\n    \n    # Load the saved file\n    checkpoint = torch.load(\"/kaggle/working/pruned_model.pth\")  # Path to model\n    \n    # Download pretrained model\n    model = models.vgg16(pretrained=True)\n    \n    # Freeze parameters so we don't backprop through them\n    for param in model.parameters():\n        param.requires_grad = False\n    \n    # Load stuff from checkpoint\n    model.class_to_idx = checkpoint['class_to_idx']\n    model.classifier = checkpoint['classifier']\n    \n    # Load state_dict, handling additional keys related to pruning\n    state_dict = checkpoint['state_dict']\n    new_state_dict = {}\n    for key, value in state_dict.items():\n        if 'mask' not in key:  # Exclude keys related to pruning\n            new_state_dict[key] = value\n    model.load_state_dict(new_state_dict)\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.878767Z","iopub.status.idle":"2024-10-01T07:48:18.879214Z","shell.execute_reply.started":"2024-10-01T07:48:18.878992Z","shell.execute_reply":"2024-10-01T07:48:18.879010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pruned_model=torch.load(\"/kaggle/working/pruned_model.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.880765Z","iopub.status.idle":"2024-10-01T07:48:18.881104Z","shell.execute_reply.started":"2024-10-01T07:48:18.880941Z","shell.execute_reply":"2024-10-01T07:48:18.880955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred(Model,Testloader):\n    all_labels = []\n    all_predictions = []\n    correct = 0\n    total = 0\n    start_time = time()\n    with torch.no_grad():\n        Model.eval()\n        for images, labels in Testloader:\n            all_labels.extend(labels.numpy())\n            images, labels = images.to(device), labels.to(device)\n            outputs = Model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            predicted_tensor_cpu = predicted.to('cpu')\n            all_predictions.extend(predicted_tensor_cpu.numpy())\n    end_time = time()\n    print(\"Time: \",end_time - start_time)\n    print('Accuracy achieved by the network on test images is: %d%%' % (100 * correct / total))\n    \n    return all_labels,all_predictions","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.882233Z","iopub.status.idle":"2024-10-01T07:48:18.882544Z","shell.execute_reply.started":"2024-10-01T07:48:18.882384Z","shell.execute_reply":"2024-10-01T07:48:18.882397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_fp32,predictions_fp32 = pred(model,testloader)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.883833Z","iopub.status.idle":"2024-10-01T07:48:18.884165Z","shell.execute_reply.started":"2024-10-01T07:48:18.884005Z","shell.execute_reply":"2024-10-01T07:48:18.884019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.885382Z","iopub.status.idle":"2024-10-01T07:48:18.885735Z","shell.execute_reply.started":"2024-10-01T07:48:18.885552Z","shell.execute_reply":"2024-10-01T07:48:18.885567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision.models as models\nfrom torchsummary import summary\n\nsummary(model, (3, 224, 224))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.887630Z","iopub.status.idle":"2024-10-01T07:48:18.888106Z","shell.execute_reply.started":"2024-10-01T07:48:18.887853Z","shell.execute_reply":"2024-10-01T07:48:18.887871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision.models as models\nimport torch.nn.utils.prune as prune\n\n# Step 1: Load the pre-trained VGG16 model from the checkpoint file\ncheckpoint = torch.load(\"/kaggle/working/model.pth\")\nmodel = models.vgg16(pretrained=True)  # Load an untrained VGG16 model\nmodel.classifier = checkpoint['classifier']  # Replace the classifier with the one from the checkpoint\nmodel.load_state_dict(checkpoint['state_dict'])  # Load the pre-trained weights\n\n# Step 2: Prune the model (example using L1 unstructured pruning)\nfor name, module in model.named_modules():\n    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n        prune.random_unstructured(module, name='weight', amount=0.5)  # Prune 50% of weights\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.889400Z","iopub.status.idle":"2024-10-01T07:48:18.889854Z","shell.execute_reply.started":"2024-10-01T07:48:18.889623Z","shell.execute_reply":"2024-10-01T07:48:18.889641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the pruned model\ntorch.save({\n    'classifier': model.classifier,\n    'state_dict': model.state_dict()\n}, 'pruned_model0.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.891271Z","iopub.status.idle":"2024-10-01T07:48:18.891604Z","shell.execute_reply.started":"2024-10-01T07:48:18.891441Z","shell.execute_reply":"2024-10-01T07:48:18.891455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# QUANTIZATION","metadata":{}},{"cell_type":"markdown","source":"## FP-16","metadata":{}},{"cell_type":"code","source":"model_fp16 = load_checkpoint()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.892889Z","iopub.status.idle":"2024-10-01T07:48:18.893241Z","shell.execute_reply.started":"2024-10-01T07:48:18.893083Z","shell.execute_reply":"2024-10-01T07:48:18.893097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.state_dict()['features.0.weight'].dtype","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.894829Z","iopub.status.idle":"2024-10-01T07:48:18.895165Z","shell.execute_reply.started":"2024-10-01T07:48:18.895007Z","shell.execute_reply":"2024-10-01T07:48:18.895020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.half()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.896076Z","iopub.status.idle":"2024-10-01T07:48:18.896390Z","shell.execute_reply.started":"2024-10-01T07:48:18.896237Z","shell.execute_reply":"2024-10-01T07:48:18.896249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fp16.half()\nmodel_fp16.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.897570Z","iopub.status.idle":"2024-10-01T07:48:18.897899Z","shell.execute_reply.started":"2024-10-01T07:48:18.897735Z","shell.execute_reply":"2024-10-01T07:48:18.897749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# weights_32 = model.state_dict()['features.0.weight']\n# weights_16 = model_fp16.state_dict()['features.0.weight']\n# weights_32_to_16 = torch.tensor(weights_32 ,dtype = torch.float16)\n# weights_16 == weights_32_to_16","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.898737Z","iopub.status.idle":"2024-10-01T07:48:18.899067Z","shell.execute_reply.started":"2024-10-01T07:48:18.898882Z","shell.execute_reply":"2024-10-01T07:48:18.898895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred_16(Model,Testloader):\n    all_labels = []\n    all_predictions = []\n\n    correct = 0\n    total = 0\n    start_time = time()\n    with torch.no_grad():\n        Model.eval()\n        for images, labels in Testloader:\n            all_labels.extend(labels.numpy())\n            images, labels = images.to(device), labels.to(device)\n            outputs = Model(images.half())\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            predicted_tensor_cpu = predicted.to('cpu')\n            all_predictions.extend(predicted_tensor_cpu.numpy())\n    end_time = time()\n    print(\"Time: \",end_time - start_time)\n    print('Accuracy achieved by the network on test images is: %d%%' % (100 * correct / total))\n    \n    return all_labels,all_predictions","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.900612Z","iopub.status.idle":"2024-10-01T07:48:18.900915Z","shell.execute_reply.started":"2024-10-01T07:48:18.900766Z","shell.execute_reply":"2024-10-01T07:48:18.900778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_fp16,predictions_fp16 = pred_16(model,testloader)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.902004Z","iopub.status.idle":"2024-10-01T07:48:18.902322Z","shell.execute_reply.started":"2024-10-01T07:48:18.902162Z","shell.execute_reply":"2024-10-01T07:48:18.902176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## FP-64","metadata":{}},{"cell_type":"code","source":"model_64 = load_checkpoint()\nmodel_64.double()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.903360Z","iopub.status.idle":"2024-10-01T07:48:18.903666Z","shell.execute_reply.started":"2024-10-01T07:48:18.903515Z","shell.execute_reply":"2024-10-01T07:48:18.903528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_64.to(device)\nall_labels_fp64 = []\nall_predictions_fp64 = []\ncorrect_fp64 = 0\ntotal_fp64 = 0\nstart_time_fp64 = time()\nwith torch.no_grad():\n    model_64.eval()\n    for images, labels in testloader:\n        all_labels_fp64.extend(labels.numpy())\n        images, labels = images.to(device), labels.to(device)\n        outputs = model_64(images.double())\n        _, predicted = torch.max(outputs.data, 1)\n        total_fp64 += labels.size(0)\n        correct_fp64 += (predicted == labels).sum().item()\n        predicted_tensor_cpu = predicted.to('cpu')\n        all_predictions_fp64.extend(predicted_tensor_cpu.numpy())\nend_time_fp64 = time()\nprint(\"Time: \",end_time_fp64 - start_time_fp64)\n\nprint('Accuracy achieved by the network on test images is: %d%%' % (100 * correct_fp64 / total_fp64))","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.905182Z","iopub.status.idle":"2024-10-01T07:48:18.905494Z","shell.execute_reply.started":"2024-10-01T07:48:18.905338Z","shell.execute_reply":"2024-10-01T07:48:18.905351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INT-8","metadata":{}},{"cell_type":"code","source":"from torch.ao.quantization import QuantStub, DeQuantStub\nimport torch\nfrom torch.ao.quantization import (\n  get_default_qconfig_mapping,\n  get_default_qat_qconfig_mapping,\n  QConfigMapping,\n)\nimport torch.ao.quantization.quantize_fx as quantize_fx\nimport copy","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.907165Z","iopub.status.idle":"2024-10-01T07:48:18.907521Z","shell.execute_reply.started":"2024-10-01T07:48:18.907342Z","shell.execute_reply":"2024-10-01T07:48:18.907356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fp32 = load_checkpoint()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.908504Z","iopub.status.idle":"2024-10-01T07:48:18.908802Z","shell.execute_reply.started":"2024-10-01T07:48:18.908654Z","shell.execute_reply":"2024-10-01T07:48:18.908666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fp32.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.910073Z","iopub.status.idle":"2024-10-01T07:48:18.910392Z","shell.execute_reply.started":"2024-10-01T07:48:18.910234Z","shell.execute_reply":"2024-10-01T07:48:18.910248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_data = next(iter(trainloader))[0][:1]  \ncalibrate_data = input_data.to(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.911793Z","iopub.status.idle":"2024-10-01T07:48:18.912146Z","shell.execute_reply.started":"2024-10-01T07:48:18.911985Z","shell.execute_reply":"2024-10-01T07:48:18.911999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_int8 = copy.deepcopy(model_fp32)\n#model_int8.to(device)\nqconfig_mapping = get_default_qconfig_mapping(\"qnnpack\")\nmodel_int8.eval()\n# prepare\nmodel_prepared = quantize_fx.prepare_fx(model_int8, qconfig_mapping, calibrate_data)\n# calibrate","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.913791Z","iopub.status.idle":"2024-10-01T07:48:18.914122Z","shell.execute_reply.started":"2024-10-01T07:48:18.913961Z","shell.execute_reply":"2024-10-01T07:48:18.913977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    for i in range(20):\n        batch = next(iter(trainloader))[0]\n        output = model_prepared(batch.to('cpu'))","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.915165Z","iopub.status.idle":"2024-10-01T07:48:18.915504Z","shell.execute_reply.started":"2024-10-01T07:48:18.915337Z","shell.execute_reply":"2024-10-01T07:48:18.915351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_quantized_static = quantize_fx.convert_fx(model_prepared)\nmodel_quantized_static.state_dict()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.916628Z","iopub.status.idle":"2024-10-01T07:48:18.916922Z","shell.execute_reply.started":"2024-10-01T07:48:18.916774Z","shell.execute_reply":"2024-10-01T07:48:18.916787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_quantized_static","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.918080Z","iopub.status.idle":"2024-10-01T07:48:18.918517Z","shell.execute_reply.started":"2024-10-01T07:48:18.918288Z","shell.execute_reply":"2024-10-01T07:48:18.918306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_quantized_static.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.919770Z","iopub.status.idle":"2024-10-01T07:48:18.920156Z","shell.execute_reply.started":"2024-10-01T07:48:18.919922Z","shell.execute_reply":"2024-10-01T07:48:18.919953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_predictions_int8 = []\nall_labels_int8 = []\ncorrect_pred = 0\ntotal_pred = 0\nstart_time_int8 = time()\nwith torch.no_grad():\n    model_quantized_static.eval()\n    for data in testloader:\n        images, labels = data\n        all_labels_int8.extend(labels.numpy())\n        #images, labels = images.to(device), labels.to(device)\n        outputs = model_quantized_static(images.to('cpu'))\n        _, predicted = torch.max(outputs.data, 1)\n        total_pred += labels.size(0)\n        correct_pred += (predicted == labels).sum().item()\n        predicted_tensor_cpu = predicted.to('cpu')\n        all_predictions_int8.extend(predicted_tensor_cpu.numpy())\nend_time_int8 = time()\nprint(\"Time: \",end_time_int8 - start_time_int8)\nprint('Accuracy achieved by the network on test images is: %d%%' % (100 * correct_pred / total_pred))","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.921970Z","iopub.status.idle":"2024-10-01T07:48:18.922437Z","shell.execute_reply.started":"2024-10-01T07:48:18.922191Z","shell.execute_reply":"2024-10-01T07:48:18.922210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_quantized_static.state_dict().keys()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.924143Z","iopub.status.idle":"2024-10-01T07:48:18.924592Z","shell.execute_reply.started":"2024-10-01T07:48:18.924358Z","shell.execute_reply":"2024-10-01T07:48:18.924376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weight_8 = model_quantized_static.state_dict()['features.0.weight']","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.925898Z","iopub.status.idle":"2024-10-01T07:48:18.926350Z","shell.execute_reply.started":"2024-10-01T07:48:18.926124Z","shell.execute_reply":"2024-10-01T07:48:18.926142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extracting outputs and weights from fp32 model","metadata":{}},{"cell_type":"code","source":"model_fp32 = load_checkpoint()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.927566Z","iopub.status.idle":"2024-10-01T07:48:18.927905Z","shell.execute_reply.started":"2024-10-01T07:48:18.927731Z","shell.execute_reply":"2024-10-01T07:48:18.927745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fp32","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.928854Z","iopub.status.idle":"2024-10-01T07:48:18.929189Z","shell.execute_reply.started":"2024-10-01T07:48:18.929031Z","shell.execute_reply":"2024-10-01T07:48:18.929045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"activation = {}\ndef get_activation(name):\n    def hook(model, input, output):\n        activation[name] = output.detach()\n    return hook","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.930182Z","iopub.status.idle":"2024-10-01T07:48:18.930601Z","shell.execute_reply.started":"2024-10-01T07:48:18.930335Z","shell.execute_reply":"2024-10-01T07:48:18.930347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_children = list(model_fp32.children())\nprint(model_children)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.931493Z","iopub.status.idle":"2024-10-01T07:48:18.931808Z","shell.execute_reply.started":"2024-10-01T07:48:18.931652Z","shell.execute_reply":"2024-10-01T07:48:18.931665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_children[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.933493Z","iopub.status.idle":"2024-10-01T07:48:18.933789Z","shell.execute_reply.started":"2024-10-01T07:48:18.933642Z","shell.execute_reply":"2024-10-01T07:48:18.933655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(model_children[0])):\n    model_children[0][i].register_forward_hook(get_activation('conv'+str(i)))","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.934892Z","iopub.status.idle":"2024-10-01T07:48:18.935235Z","shell.execute_reply.started":"2024-10-01T07:48:18.935077Z","shell.execute_reply":"2024-10-01T07:48:18.935090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fp32.to(device)\ncorrect = 0\ntotal = 0\ncount = 1\nnew = []\nall_labels = []\nall_predictions = []\nwith torch.no_grad():\n    model_fp32.eval()\n    for images, labels in testloader:\n        new.extend(images)\n        all_labels.extend(labels.numpy())\n        images, labels = images.to(device), labels.to(device)\n        outputs = model_fp32(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        predicted_tensor_cpu = predicted.to('cpu')\n        all_predictions.extend(predicted_tensor_cpu.numpy())\n        if count == 1:\n            break\n\nprint('Accuracy achieved by the network on test images is: %d%%' % (100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.936586Z","iopub.status.idle":"2024-10-01T07:48:18.936877Z","shell.execute_reply.started":"2024-10-01T07:48:18.936730Z","shell.execute_reply":"2024-10-01T07:48:18.936742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(activation)):\n    print(i,':',activation['conv'+str(i)].shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.938563Z","iopub.status.idle":"2024-10-01T07:48:18.938861Z","shell.execute_reply.started":"2024-10-01T07:48:18.938713Z","shell.execute_reply":"2024-10-01T07:48:18.938725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"activation.keys()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.939634Z","iopub.status.idle":"2024-10-01T07:48:18.939969Z","shell.execute_reply.started":"2024-10-01T07:48:18.939787Z","shell.execute_reply":"2024-10-01T07:48:18.939800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fp32.state_dict().keys()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.941535Z","iopub.status.idle":"2024-10-01T07:48:18.941988Z","shell.execute_reply.started":"2024-10-01T07:48:18.941746Z","shell.execute_reply":"2024-10-01T07:48:18.941764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extracting weights for testing ","metadata":{}},{"cell_type":"code","source":"# Extracting weights and bias to check only the shape and number of filters\nweights_0 = model_fp32.state_dict()['features.0.weight']\nbias_0 = model_fp32.state_dict()['features.0.bias']","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.943380Z","iopub.status.idle":"2024-10-01T07:48:18.943817Z","shell.execute_reply.started":"2024-10-01T07:48:18.943595Z","shell.execute_reply":"2024-10-01T07:48:18.943613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights_0.shape # --> torch.Size([64, 3, 3, 3]) ==> 64 filters of 3*3*3","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.944875Z","iopub.status.idle":"2024-10-01T07:48:18.945325Z","shell.execute_reply.started":"2024-10-01T07:48:18.945107Z","shell.execute_reply":"2024-10-01T07:48:18.945125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights_10.shape # --> torch.Size([256, 128, 3, 3]) 256 filters of 128*3*3","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.946614Z","iopub.status.idle":"2024-10-01T07:48:18.947061Z","shell.execute_reply.started":"2024-10-01T07:48:18.946820Z","shell.execute_reply":"2024-10-01T07:48:18.946838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CONV FUNCTION","metadata":{}},{"cell_type":"code","source":"def ReLU(z):\n    return np.maximum(0, z)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.948706Z","iopub.status.idle":"2024-10-01T07:48:18.949164Z","shell.execute_reply.started":"2024-10-01T07:48:18.948915Z","shell.execute_reply":"2024-10-01T07:48:18.948953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv(image, input_shape, n_filters, filters, bias, kernel_size, stride, padding=False):\n    if(padding):\n        image = np.pad(image, ((0, 0), (1, 1),(1, 1)), mode='constant', constant_values=0)\n    img_h, img_w = image.shape[1:]\n    filter_h, filter_w = kernel_size[:]\n\n    #filters = np.random.rand(n_filters, kernel_size[0], kernel_size[1], input_shape[2])\n\n    output_fmaps = []\n    fmap_h = (img_h - filter_h)//stride + 1\n    fmap_w =  (img_w - filter_w)//stride + 1\n\n    for n, filter in enumerate(filters[: , : , :, ]):\n        fmap = np.zeros((fmap_h, fmap_w))\n\n        sum = 0\n        for i in range(0, stride*fmap_h, stride):\n            for j in range(0, stride*fmap_w, stride):\n                input_patch = image[:, i:i+filter_h, j:j+filter_w]\n                sum = np.sum(input_patch * filter) + bias[n]\n                fmap[i//stride, j//stride] = ReLU(sum)\n        output_fmaps.append(fmap)\n\n    return output_fmaps","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.950642Z","iopub.status.idle":"2024-10-01T07:48:18.951089Z","shell.execute_reply.started":"2024-10-01T07:48:18.950850Z","shell.execute_reply":"2024-10-01T07:48:18.950868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MAX POOLING ","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n\n# def maxPool2D(fmaps, kernel_size, stride, padding=0):\n\n#     # Add padding to the input image\n#     padded_image = np.pad(image, pad_width=padding, mode='constant', constant_values=0)\n\n#     # Initialize output image\n#     output_image_maps = []\n#     output_height = (padded_image.shape[0] - kernel_size) // stride + 1\n#     output_width = (padded_image.shape[1] - kernel_size) // stride + 1\n#     output_image = np.zeros((output_height, output_width))\n\n#     # Perform max pooling\n#     for i in range(0, padded_image.shape[0] - kernel_size + 1, stride):\n#         for j in range(0, padded_image.shape[1] - kernel_size + 1, stride):\n#             output_image[i // stride, j // stride] = np.max(padded_image[i:i + kernel_size, j:j + kernel_size])\n\n#     return output_image\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.952043Z","iopub.status.idle":"2024-10-01T07:48:18.952473Z","shell.execute_reply.started":"2024-10-01T07:48:18.952245Z","shell.execute_reply":"2024-10-01T07:48:18.952263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparing Model outputs with custom conv function output","metadata":{}},{"cell_type":"code","source":"img_index = 3 # range from 0 to 49 -> 50 different images","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.954241Z","iopub.status.idle":"2024-10-01T07:48:18.954686Z","shell.execute_reply.started":"2024-10-01T07:48:18.954451Z","shell.execute_reply":"2024-10-01T07:48:18.954477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img = new[img_index].numpy()\nio.imshow(test_img[0]) # test image has 3 channels,displaying only only 1 channel\nio.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.956194Z","iopub.status.idle":"2024-10-01T07:48:18.956627Z","shell.execute_reply.started":"2024-10-01T07:48:18.956400Z","shell.execute_reply":"2024-10-01T07:48:18.956417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights = model_fp32.state_dict()['features.0.weight']\nbias = model_fp32.state_dict()['features.0.bias']\nweights = weights.to('cpu').numpy()\nbias = bias.to('cpu').numpy()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.957759Z","iopub.status.idle":"2024-10-01T07:48:18.958211Z","shell.execute_reply.started":"2024-10-01T07:48:18.957985Z","shell.execute_reply":"2024-10-01T07:48:18.958004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing custom conv function for 1 image\nstart = time()\nlayer_1_fmaps = conv(test_img, test_img.shape, weights.shape[0], weights, bias, weights.shape[2:], stride=1,padding=True)\nend = time()\nprint(f\"Time taken : {end-start}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.959579Z","iopub.status.idle":"2024-10-01T07:48:18.960031Z","shell.execute_reply.started":"2024-10-01T07:48:18.959786Z","shell.execute_reply":"2024-10-01T07:48:18.959805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_1_fmaps[0].dtype","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.961210Z","iopub.status.idle":"2024-10-01T07:48:18.961686Z","shell.execute_reply.started":"2024-10-01T07:48:18.961429Z","shell.execute_reply":"2024-10-01T07:48:18.961448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_1_fmaps = [arr.astype(np.float32) for arr in layer_1_fmaps]","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.962911Z","iopub.status.idle":"2024-10-01T07:48:18.963260Z","shell.execute_reply.started":"2024-10-01T07:48:18.963105Z","shell.execute_reply":"2024-10-01T07:48:18.963119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the output of required layer for 50 images from model\nlayer1 = activation['conv0'].cpu().numpy() ","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.964351Z","iopub.status.idle":"2024-10-01T07:48:18.964671Z","shell.execute_reply.started":"2024-10-01T07:48:18.964514Z","shell.execute_reply":"2024-10-01T07:48:18.964527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"io.imshow(layer_1_fmaps[1]) # from custom function\nio.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.966319Z","iopub.status.idle":"2024-10-01T07:48:18.966654Z","shell.execute_reply.started":"2024-10-01T07:48:18.966492Z","shell.execute_reply":"2024-10-01T07:48:18.966506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"io.imshow(layer1[3][1] )\nio.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.967832Z","iopub.status.idle":"2024-10-01T07:48:18.968160Z","shell.execute_reply.started":"2024-10-01T07:48:18.968003Z","shell.execute_reply":"2024-10-01T07:48:18.968017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"io.imshow(layer1[3][1] - layer_1_fmaps[1]) # difference in fp32\nio.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.969552Z","iopub.status.idle":"2024-10-01T07:48:18.969872Z","shell.execute_reply.started":"2024-10-01T07:48:18.969715Z","shell.execute_reply":"2024-10-01T07:48:18.969728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer1[3][1] # one ofmap out of 64 maps for an image out of 50 images","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.971202Z","iopub.status.idle":"2024-10-01T07:48:18.971530Z","shell.execute_reply.started":"2024-10-01T07:48:18.971367Z","shell.execute_reply":"2024-10-01T07:48:18.971380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_1_fmaps[1] # one ofmap out of 64 maps","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.972776Z","iopub.status.idle":"2024-10-01T07:48:18.973121Z","shell.execute_reply.started":"2024-10-01T07:48:18.972955Z","shell.execute_reply":"2024-10-01T07:48:18.972971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_1_fmaps[0].dtype == layer1[3][0].dtype","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.975268Z","iopub.status.idle":"2024-10-01T07:48:18.975796Z","shell.execute_reply.started":"2024-10-01T07:48:18.975492Z","shell.execute_reply":"2024-10-01T07:48:18.975511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_1_fmaps[0].shape == layer1[3][0].shape","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.976727Z","iopub.status.idle":"2024-10-01T07:48:18.977328Z","shell.execute_reply.started":"2024-10-01T07:48:18.976949Z","shell.execute_reply":"2024-10-01T07:48:18.976968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_1_fmaps = [arr.astype(np.int8) for arr in layer_1_fmaps]\nlayer1[3] = [arr.astype(np.int8) for arr in layer1[3]]","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.978898Z","iopub.status.idle":"2024-10-01T07:48:18.979346Z","shell.execute_reply.started":"2024-10-01T07:48:18.979127Z","shell.execute_reply":"2024-10-01T07:48:18.979145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_1_fmaps == layer1[3]","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.980522Z","iopub.status.idle":"2024-10-01T07:48:18.980974Z","shell.execute_reply.started":"2024-10-01T07:48:18.980728Z","shell.execute_reply":"2024-10-01T07:48:18.980746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Storing the weights in a pt file","metadata":{}},{"cell_type":"code","source":"weights = model_fp32.state_dict()['features.0.weight']\n\n# Create a simple script module to hold the weights\nclass MyScriptModule(torch.jit.ScriptModule):\n    def __init__(self, weights):\n        super(MyScriptModule, self).__init__()\n        self.weights = torch.nn.Parameter(weights)\n\n    @torch.jit.script_method\n    def forward(self):\n        return self.weights\n\n# Instantiate the script module and save it\nscript_module = MyScriptModule(weights)\nscript_module.save(\"features.0.weight.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-10-01T07:48:18.982376Z","iopub.status.idle":"2024-10-01T07:48:18.982729Z","shell.execute_reply.started":"2024-10-01T07:48:18.982562Z","shell.execute_reply":"2024-10-01T07:48:18.982576Z"},"trusted":true},"execution_count":null,"outputs":[]}]}